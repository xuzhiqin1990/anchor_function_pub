{
  "train_data_size": 4000,
  "test_data_size": 100,
  "seq_len": 9,
  "data_min": 20,
  "data_max": 100,
  "data_percent": [0.5, 0.5],
  "data_mode": ["abab", "abba"],
  "target": "context",
  "batch_size": 100,
  "vocab_size": 201,
  "max_pos": 20,
  "d_model": 400,
  "d_feedforward": 1200,
  "d_k": 64,
  "d_v": 64,
  "n_layers": 4,
  "n_heads": 4,
  "clip": 1,
  "n_epoch": 4000,
  "lr": 2e-05,
  "lr_decay_step": 1000,
  "lr_decay_rate": 1,
  "seed": 1,
  "scheduler": "GradualWarmupScheduler_CosineAnnealingLR",
  "model": "GPT",
  "optim": "Adam",
  "save_model_epoch": 100,
  "print_loss_epoch": 10,
  "print_acc_epoch": 100,
  "plot_loss_acc_epoch": 500,
  "prefix": " ",
  "suffix": " ",
  "dir_suffix": "上下文学习_4层_warmup_cos_lr_2e-5",
  "exp_index": 0,
  "working_dir": "./result/GPT_上下文学习_4层_warmup_cos_lr_2e-5/context-seed_1-N_4000/"
}
